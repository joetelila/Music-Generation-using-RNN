{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad812dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmony Team\n",
    "# Nov. 10 - 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe78f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/opt/anaconda3/envs/cnr/bin/python3 -m pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b173cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "import json\n",
    "import os\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, Audio\n",
    "from music21 import note , chord , stream , instrument , converter   \n",
    "import mido\n",
    "# from midi2audio import FluidSynth          # to convert midi to wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c28089-21e7-4859-9057-8d73724e9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network output are the classes, so encode into one hot vector\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d2fb9-6c5c-4b27-9ded-d447624dd78f",
   "metadata": {},
   "source": [
    "## Data preparation and visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26881cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = mido.MidiFile('dataset_2/midi_songs/0fithos.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5381b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258.2724710000016"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid.length # in seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15accf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "music21.stream.base.Score"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading MidiFile\n",
    "# parse the encoded data in a file object to midi stream\n",
    "midi = converter.parse('dataset_2/midi_songs/0fithos.mid')\n",
    "type(midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac93be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#midi.show('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ff572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169\n"
     ]
    }
   ],
   "source": [
    "# Flat all the elements - notes/chords\n",
    "notes_to_parse = midi.flat.notes\n",
    "print(len(notes_to_parse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e6a3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<music21.chord.Chord E3 A3> 4.0\n",
      "<music21.note.Note E> 4.0\n",
      "<music21.chord.Chord A1 E2> 4.0\n",
      "<music21.chord.Chord E3 A3> 5.0\n",
      "<music21.chord.Chord A1 E2> 5.0\n",
      "<music21.chord.Chord A1 E2> 5.5\n",
      "<music21.chord.Chord A1 E2> 6.0\n",
      "<music21.chord.Chord A1 E2> 7.0\n",
      "<music21.chord.Chord A1 E2> 7.5\n",
      "<music21.chord.Chord E3 B3> 8.0\n",
      "<music21.chord.Chord A1 E2> 8.0\n",
      "<music21.chord.Chord E3 B3> 9.0\n",
      "<music21.chord.Chord A1 E2> 9.0\n",
      "<music21.chord.Chord A1 E2> 9.5\n",
      "<music21.chord.Chord A1 E2> 10.0\n"
     ]
    }
   ],
   "source": [
    "for element in notes_to_parse[:15]:\n",
    "    print(element , element.offset)   # Offset refers to where the note is located in the piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c19bfdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(notes_to_parse[1].pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881000e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 9]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_to_parse[50].normalOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e32ac151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<music21.pitch.Pitch E2>, 'E2')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pitch refers to the frequency of the sound, or how high or low a particular note is \n",
    "# and is represented with the letters [A, B, C, D, E, F, G], with A being the highest and G being the lowest\n",
    "notes_to_parse[1].pitch , str(notes_to_parse[1].pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b084d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_demo = []\n",
    "\n",
    "for element in notes_to_parse:\n",
    "    \n",
    "    # if the element is a Note , then store it's Pitch\n",
    "    if isinstance(element , note.Note):\n",
    "        notes_demo.append(str(element.pitch))\n",
    "        \n",
    "    # if the element is a Chord , split each of the note of the chord and join them with +\n",
    "    elif isinstance(element , chord.Chord):\n",
    "        notes_demo.append('+'.join(str(n) for n in element.normalOrder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "684ae489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notes_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "179ae367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4+9', '4+9', '4+9', '4+9', 'E2', '4+9', '4+9', '4+9', '4+9', '4+9', 'E5', 'F5', 'G#5', 'A5', '4+9', '4+9', '5+11', '4+9']\n"
     ]
    }
   ],
   "source": [
    "print(notes_demo[32:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3529a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing midi file ordered by name.\n",
    "root_midi = \"dataset_2/midi_songs/\"\n",
    "midi_file_dir = os.listdir(root_midi)\n",
    "if '.ipynb_checkpoints' in midi_file_dir:\n",
    "    midi_file_dir.remove('.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dc68a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(midi_file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19de6004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Parcing:  98.91 % complete"
     ]
    }
   ],
   "source": [
    "# Get all the notes and chords from the midi files in the ./midi_songs directory \n",
    "notes = []\n",
    "#total_midi = len(p.glob(\"*.mid\"))\n",
    "for idx, file in enumerate(midi_file_dir):\n",
    "    midi = converter.parse(root_midi+file)\n",
    "    # print(f\"parsing {file}\" , end = \"  \")\n",
    "    \n",
    "    elements_to_parse = midi.flat.notes\n",
    "    # print(f\"length {len(elements_to_parse)}\")\n",
    "    \n",
    "    for element in elements_to_parse:\n",
    "        \n",
    "        # if the element is a Note, then store it's Pitch\n",
    "        if isinstance(element , note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "            \n",
    "        # if the element is a Chord , then split each of the note and join with +\n",
    "        elif isinstance(element , chord.Chord):\n",
    "            notes.append(\"+\".join(str(n) for n in element.normalOrder))\n",
    "    print('\\r', 'Parcing: ', np.round((idx/len(midi_file_dir))*100,2), '% complete', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9eabd3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60866"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f86abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/notes\" , \"wb\") as file:\n",
    "    pickle.dump(notes , file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fb696c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/notes\" , \"rb\") as file:\n",
    "    notes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77d08e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total notes:  60764\n",
      "Unique notes:  398\n"
     ]
    }
   ],
   "source": [
    "print(\"Total notes: \" , len(notes))\n",
    "print(\"Unique notes: \" , len(set(notes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d5a0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e167b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254bcd1",
   "metadata": {},
   "source": [
    "## PREPARE SEQUENTIAL DATA FOR LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5443f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all pitch names (unique classes)\n",
    "pitchnames = sorted(set(notes))\n",
    "\n",
    "# create a dictionary to map pitches to integers\n",
    "note_to_int = dict((element , idx) for idx , element in enumerate(pitchnames))\n",
    "\n",
    "# create a reverse mapping\n",
    "int_to_note = {idx:element for element , idx in note_to_int.items()}\n",
    "\n",
    "assert len(note_to_int) == n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b436d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all pitch names (unique classes).\n",
    "pitchnames = sorted(set(notes))\n",
    "\n",
    "# create a dictionary to map pitches to integers.\n",
    "note_to_int = dict((element , idx) for idx , element in enumerate(pitchnames))\n",
    "\n",
    "# create a reverse mapping.\n",
    "int_to_note = {idx:element for element , idx in note_to_int.items()}\n",
    "\n",
    "assert len(note_to_int) == n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee97bee6-8cc6-4109-aa44-d524679f802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_set(notes, sequence_len = 100):\n",
    "    \n",
    "    # sequence_len -  How many elements LSTM input should consider\n",
    "    \n",
    "    network_input = []     # input sequence data\n",
    "    network_output = []    # output data\n",
    "\n",
    "    for i in range(len(notes) - sequence_len):\n",
    "        seq_in = notes[i : i+sequence_len]         # contains 100 values\n",
    "        seq_out = notes[i+sequence_len]\n",
    "\n",
    "        network_input.append([note_to_int[n] for n in seq_in])\n",
    "        network_output.append(note_to_int[seq_out])\n",
    "        \n",
    "    return network_input, network_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bff35418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60664, 60664)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input,network_output= prepare_training_set(notes, sequence_len = 100)\n",
    "len(network_input) , len(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "530b76a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60664, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape input data into a shape compatible with LSTM layers\n",
    "_network_input = np.reshape(network_input , (*(np.asarray(network_input).shape) , 1))  # input_samples, sequence_len, 1\n",
    "print(_network_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01d914c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_network_input = _network_input/float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3345c802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95979899],\n",
       "       [0.95979899],\n",
       "       [0.83668342],\n",
       "       [0.95979899],\n",
       "       [0.99246231],\n",
       "       [0.97738693],\n",
       "       [0.96231156],\n",
       "       [0.95979899],\n",
       "       [0.99246231],\n",
       "       [0.98994975]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_network_input[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35926312",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_output = to_categorical(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2021fe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60766, 100, 1)\n",
      "(60766, 359)\n"
     ]
    }
   ],
   "source": [
    "print(normalised_network_input.shape)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acba6775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60766, 100, 1)\n",
      "(60766, 359)\n"
     ]
    }
   ],
   "source": [
    "print(normalised_network_input.shape)\n",
    "print(network_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75890ece",
   "metadata": {},
   "source": [
    "#### DEFINE MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a24f39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(unit_layer1=64,unit_layer2=32,unit_layer3=512, dense_layer=128,drop_out=0.3):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = unit_layer1 , input_shape = (normalised_network_input.shape[1], normalised_network_input.shape[2])\n",
    "                   , return_sequences = True))\n",
    "    model.add(Dropout(drop_out))\n",
    "\n",
    "    model.add(LSTM(units = unit_layer2 , return_sequences = True))\n",
    "    model.add(Dropout(drop_out))\n",
    "\n",
    "    model.add(LSTM(units = unit_layer3))\n",
    "    model.add(Dense(dense_layer))\n",
    "    model.add(Dropout(drop_out))\n",
    "\n",
    "    model.add(Dense(n_vocab , activation = 'softmax'))\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79cc095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(unit_layer1=64,unit_layer2=32,unit_layer3=512, dense_layer=128,drop_out=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b5d3e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 100, 64)           16896     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100, 64)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 100, 32)           12416     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100, 32)           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 512)               1116160   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 359)               46311     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,257,447\n",
      "Trainable params: 1,257,447\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6a9f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = ModelCheckpoint(\"weights.h5\", monitor = 'loss', save_best_only=True, mode = 'min')\n",
    "hist = model.fit(normalised_network_input, network_output, epochs = 100, batch_size = 64)#, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74e80e-a339-4dd9-a424-efd87a16371e",
   "metadata": {},
   "source": [
    "## Hyperparameter search using grid search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c072b-d0a4-44bd-b4cf-257add60b8c7",
   "metadata": {},
   "source": [
    "Hyperparameter tuning involves adjusting certain parameters of a machine learning model to improve its performance. In the case of an LSTM (Long Short-Term Memory) model, these parameters may include the number of hidden units, the presence and size of dense layers, and the dropout percentage. By experimenting with different combinations of these hyperparameters, it is possible to achieve better model accuracy and generalization to new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5604cde-35f3-436e-8546-4496595fb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_layer1 = [128,64,32]\n",
    "unit_layer2 = [128,64,32]\n",
    "unit_layer3 = [128,64,32]\n",
    "dense_layer = [128,64]\n",
    "drop_out = [0.5,0.3,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74c4a81e-cee3-4788-a69e-96d12cfbda1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_combinations = list(itertools.product(unit_layer1,unit_layer2,unit_layer3,dense_layer,drop_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fcf44b7d-d70a-47d9-8eb7-f2474fa714ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 100, 128)          66560     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 100, 128)          131584    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 359)               46311     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 392,551\n",
      "Trainable params: 392,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hist = []\n",
    "for _conf in possible_combinations:\n",
    "    unit_layer1=_conf[0]\n",
    "    unit_layer2=_conf[1]\n",
    "    unit_layer3=_conf[2]\n",
    "    dense_layer=_conf[3]\n",
    "    drop_out=_conf[4]\n",
    "    model = create_model(unit_layer1,unit_layer2,unit_layer3, dense_layer,drop_out)\n",
    "    _conf_hist = model.fit(normalised_network_input, network_output, epochs = 100, batch_size = 64) #, callbacks = [checkpoint]\n",
    "    hist.append(_conf_hist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5111a43e",
   "metadata": {},
   "source": [
    "## Generating Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8751ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/model_inputs\" , \"rb\") as file:\n",
    "    model_notes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db4ef8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/notes\" , \"rb\") as file:\n",
    "    notes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92329910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab = len(set(notes))\n",
    "n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24937697",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/int_to_note\" , \"rb\") as file:\n",
    "    int_to_note = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d44a21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = model_notes[np.random.randint(0 , len(model_notes)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ad95327",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern.append(111111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "903896b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Generate notes from the neural network based on a sequence of notes\"\"\"\n",
    "\n",
    "# pick a random sequence from the input as a starting point for the prediction\n",
    "# inital sequence/pattern\n",
    "seed_pattern = model_notes[np.random.randint(0 , len(model_notes)-1)]    # 100\n",
    "\n",
    "predicted_outputs = []\n",
    "\n",
    "# generate 500 notes\n",
    "for indx in range(10):\n",
    "    inp_seq = np.reshape(pattern , (1, len(pattern), 1))   # convert to desired input shape for model\n",
    "    inp_seq = inp_seq/float(n_vocab)  # normalize\n",
    "    \n",
    "    prediction = model_notes[np.random.randint(0 , len(model_notes)-1)]#model.predict(inp_seq)\n",
    "    pred_idx = np.argmax(prediction)\n",
    "    pred_note = int_to_note[pred_idx]\n",
    "    \n",
    "    predicted_outputs.append(pred_note)\n",
    "    \n",
    "    # remove the first note of the sequence and insert the output of the previous iteration at the end of the sequence\n",
    "    seed_pattern.append(pred_idx)\n",
    "    seed_pattern = seed_pattern[indx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ab3b18e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['10+2+3', '0+3+5', '0+2+3+7', '0+6', '10+11+1+3+4+6', '1+3+6', '11+1+4', '0+1+5', '0+3+7', '11+0+4']\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_outputs))\n",
    "print(predicted_outputs[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "db790759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi():\n",
    "    # convert the output predictions to notes \n",
    "    offset = 0 \n",
    "    output_notes = []\n",
    "    \n",
    "    for pattern in predicted_outputs:\n",
    "        \n",
    "        # if the pattern is a chord, first split the string up into an array of notes\n",
    "        if ('+' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('+')\n",
    "            \n",
    "            # Then we loop through the string representation of each note and create a Note object for each of them\n",
    "            notes_tmp = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))         \n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes_tmp.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes_tmp)   # create Chords from list of notes(strings of pitch names)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        \n",
    "        # if pattern is a Note, create a Note object using string representation of the pitch contained in the predicted pattern\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note) \n",
    "            \n",
    "        offset += 0.5   # Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ec2094e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'midi_gen/test_output_stream.mid'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a midi stream object from the generated notes \n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write(fmt = 'midi', fp = 'midi_gen/test_output_stream.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3e9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:16:26) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6c2c1ca8bb40246a64d5fbf4521245c8b17f4d1e024ecbfd7ea02cf550eac10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
